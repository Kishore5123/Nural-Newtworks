{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1b9e383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f63e74e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"gas_turbines.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0054f7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3837751c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8a05fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'TEY', 'CDP', 'CO',\n",
       "       'NOX'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdcdef10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "      <th>TEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "      <td>114.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "      <td>114.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "      <td>114.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "      <td>111.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "      <td>111.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "      <td>110.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "      <td>110.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "      <td>111.58</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX     TEY  \n",
       "0      82.722  114.70  \n",
       "1      82.776  114.72  \n",
       "2      82.468  114.71  \n",
       "3      82.670  114.72  \n",
       "4      82.311  114.72  \n",
       "...       ...     ...  \n",
       "15034  79.559  111.61  \n",
       "15035  79.917  111.78  \n",
       "15036  90.912  110.19  \n",
       "15037  93.227  110.74  \n",
       "15038  92.498  111.58  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.loc[:,['AT', 'AP', 'AH', 'AFDP', 'GTEP', 'TIT', 'TAT', 'CDP', 'CO','NOX','TEY']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9909ddb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     CDP      CO  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  10.605  3.1547   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  10.598  3.2363   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  10.601  3.2012   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  10.606  3.1923   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  10.612  3.2484   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  10.400  4.5186   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  10.433  4.8470   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  10.483  7.9632   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  10.533  6.2494   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  10.583  4.9816   \n",
       "\n",
       "          NOX  \n",
       "0      82.722  \n",
       "1      82.776  \n",
       "2      82.468  \n",
       "3      82.670  \n",
       "4      82.311  \n",
       "...       ...  \n",
       "15034  79.559  \n",
       "15035  79.917  \n",
       "15036  90.912  \n",
       "15037  93.227  \n",
       "15038  92.498  \n",
       "\n",
       "[15039 rows x 10 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=data.iloc[:,0:-1]\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09183c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        114.70\n",
       "1        114.72\n",
       "2        114.71\n",
       "3        114.72\n",
       "4        114.72\n",
       "          ...  \n",
       "15034    111.61\n",
       "15035    111.78\n",
       "15036    110.19\n",
       "15037    110.74\n",
       "15038    111.58\n",
       "Name: TEY, Length: 15039, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y=data.iloc[:,-1]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "474a7838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15039, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "397b150e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "TEY     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "73f5369f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a32a7cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING MODEL \n",
    "\n",
    "model=tf.keras.models.Sequential()\n",
    "model.adata(tf.keras.layers.Dense(15,input_dim=10,activation ='ReLU'))\n",
    "model.adata(tf.keras.layers.Dense(10,activation='ReLU'))\n",
    "model.adata(tf.keras.layers.Dense(1,activation='ReLU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "091f7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 15)                165       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                160       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 11        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 336\n",
      "Trainable params: 336\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8df484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse',optimizer='adam',metrics=['mse','mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2e96f24f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 26/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 27/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 28/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 29/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 30/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 31/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 32/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8828 - mse: 18278.8828 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 33/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 34/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 35/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 36/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 37/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 38/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 39/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 40/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 41/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 42/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 43/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8828 - mse: 18278.8828 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 44/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 45/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8848 - mse: 18278.8848 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 47/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 48/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 49/50\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n",
      "Epoch 50/50\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 18278.8867 - mse: 18278.8867 - mae: 134.2709 - val_loss: 18169.9980 - val_mse: 18169.9980 - val_mae: 133.8587\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(x_train,y_train,validation_data=(x_test,y_test),epochs=50,batch_size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b848203c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights(\"mywt.kmw\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e9952253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 310us/step - loss: 18278.8887 - mse: 18278.8887 - mae: 134.2709\n",
      "mse: 1827888.87%\n"
     ]
    }
   ],
   "source": [
    "scores=model.evaluate(x_train,y_train)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0584697d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "65a64602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e552bf2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mse'])\n",
    "plt.plot(history.history['val_mse'])\n",
    "plt.title('model mse')\n",
    "plt.ylabel('mse')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train','test'],loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "26367305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['mae'])\n",
    "plt.plot(history.history['val_mae'])\n",
    "plt.title('model mae')\n",
    "plt.ylabel('mae')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "863ff555",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6722f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 243us/step\n",
      "94/94 [==============================] - 0s 271us/step\n",
      "Training set rmse: 135.199, Testing set rmse: 134.796\n"
     ]
    }
   ],
   "source": [
    "y_train_pred=model.predict(x_train)\n",
    "y_test_pred=model.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_rmse=mean_squared_error(y_train,y_train_pred,squared=False)\n",
    "test_rmse=mean_squared_error(y_test,y_test_pred,squared=False)\n",
    "\n",
    "print('Training set rmse: %.3f, Testing set rmse: %.3f' % (train_rmse,test_rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c495f9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomzied search  cv\n",
    "from sklearn.model_selection import RandomizedSearchCV, KFold\n",
    "from keras.optimizers import Adam\n",
    "from keras.wrappers.scikit_learn import KerasRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4b9fb890",
   "metadata": {},
   "outputs": [],
   "source": [
    "def keras_reg_model(learning_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.adata(tf.keras.layers.Dense(neuron1,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.adata(tf.keras.layers.Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.adata(tf.keras.layers.Dense(1,activation = 'linear'))\n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'mse',optimizer = adam,metrics = ['mse','mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "934c8e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_reg = KerasRegressor(build_fn = keras_reg_model,verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "892f1c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2023-06-05 22:11:27.815046: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2023-06-05 22:11:27.830800: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-05 22:11:27.842805: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-05 22:11:27.866114: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-05 22:11:27.913355: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2023-06-05 22:11:28.005404: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "2023-06-05 22:11:28.036188: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-05 22:11:28.087408: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_test_function.<locals>.test_function at 0x1429085e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:tensorflow:5 out of the last 15 calls to <function Model.make_test_function.<locals>.test_function at 0x1607ec820> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "WARNING:tensorflow:5 out of the last 32 calls to <function Model.make_test_function.<locals>.test_function at 0x16261bbe0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/Users/kishoresuddapalli/anaconda3/lib/python3.10/site-packages/keras/optimizers/optimizer_v2/adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "batch_size = [10,50,100,500,1000,2000]\n",
    "epochs = [25,50,80,100,150]\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "\n",
    "activation_function = ['elu','relu','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "neuron1 = [5,10,20,30]\n",
    "neuron2 = [5,10,20,30]\n",
    "\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator = keras_reg,param_distributions = param_grids,cv = 5,n_jobs=-1,verbose = 10,\n",
    "                                   random_state=40)\n",
    "random_result = random_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e77a696a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: -2.920744204521179\n",
      "Best parameters: {'neuron2': 5, 'neuron1': 20, 'learning_rate': 0.01, 'init': 'uniform', 'epochs': 100, 'batch_size': 500, 'activation_function': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "print('Best score:',random_result.best_score_)\n",
    "print('Best parameters:',random_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "145bfc50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 2342.1084 - mse: 2342.1084 - mae: 36.6601 - val_loss: 239.7758 - val_mse: 239.7758 - val_mae: 11.7646\n",
      "Epoch 2/100\n",
      "25/25 [==============================] - 0s 916us/step - loss: 300.1352 - mse: 300.1352 - mae: 13.9221 - val_loss: 230.2430 - val_mse: 230.2430 - val_mae: 11.5955\n",
      "Epoch 3/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 227.6703 - mse: 227.6703 - mae: 11.3335 - val_loss: 227.1564 - val_mse: 227.1564 - val_mae: 12.0186\n",
      "Epoch 4/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 210.1949 - mse: 210.1949 - mae: 10.5266 - val_loss: 202.9902 - val_mse: 202.9902 - val_mae: 10.3220\n",
      "Epoch 5/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 196.7530 - mse: 196.7530 - mae: 10.3064 - val_loss: 187.6953 - val_mse: 187.6953 - val_mae: 9.8671\n",
      "Epoch 6/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 179.2684 - mse: 179.2684 - mae: 9.7922 - val_loss: 168.8078 - val_mse: 168.8078 - val_mae: 9.3139\n",
      "Epoch 7/100\n",
      "25/25 [==============================] - 0s 990us/step - loss: 155.7499 - mse: 155.7499 - mae: 9.1646 - val_loss: 146.8621 - val_mse: 146.8621 - val_mae: 9.1176\n",
      "Epoch 8/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 123.0525 - mse: 123.0525 - mae: 8.2562 - val_loss: 100.0752 - val_mse: 100.0752 - val_mae: 7.4337\n",
      "Epoch 9/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 82.9828 - mse: 82.9828 - mae: 6.9180 - val_loss: 68.6188 - val_mse: 68.6188 - val_mae: 6.9504\n",
      "Epoch 10/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 49.8802 - mse: 49.8802 - mae: 5.3824 - val_loss: 33.9480 - val_mse: 33.9480 - val_mae: 4.6377\n",
      "Epoch 11/100\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 32.4470 - mse: 32.4470 - mae: 4.1673 - val_loss: 36.0208 - val_mse: 36.0208 - val_mae: 4.8252\n",
      "Epoch 12/100\n",
      "25/25 [==============================] - 0s 966us/step - loss: 23.9370 - mse: 23.9370 - mae: 3.4310 - val_loss: 16.3180 - val_mse: 16.3180 - val_mae: 3.0533\n",
      "Epoch 13/100\n",
      "25/25 [==============================] - 0s 870us/step - loss: 17.8970 - mse: 17.8970 - mae: 2.8940 - val_loss: 33.3055 - val_mse: 33.3055 - val_mae: 4.9366\n",
      "Epoch 14/100\n",
      "25/25 [==============================] - 0s 888us/step - loss: 22.0184 - mse: 22.0184 - mae: 3.4834 - val_loss: 19.0169 - val_mse: 19.0169 - val_mae: 3.5976\n",
      "Epoch 15/100\n",
      "25/25 [==============================] - 0s 872us/step - loss: 14.2351 - mse: 14.2351 - mae: 2.7482 - val_loss: 10.6545 - val_mse: 10.6545 - val_mae: 2.5772\n",
      "Epoch 16/100\n",
      "25/25 [==============================] - 0s 861us/step - loss: 10.6640 - mse: 10.6640 - mae: 2.3196 - val_loss: 10.8522 - val_mse: 10.8522 - val_mae: 2.5510\n",
      "Epoch 17/100\n",
      "25/25 [==============================] - 0s 873us/step - loss: 8.3770 - mse: 8.3770 - mae: 2.0455 - val_loss: 7.3574 - val_mse: 7.3574 - val_mae: 2.1430\n",
      "Epoch 18/100\n",
      "25/25 [==============================] - 0s 872us/step - loss: 8.5549 - mse: 8.5549 - mae: 2.1644 - val_loss: 10.4294 - val_mse: 10.4294 - val_mae: 2.6854\n",
      "Epoch 19/100\n",
      "25/25 [==============================] - 0s 902us/step - loss: 10.0037 - mse: 10.0037 - mae: 2.4259 - val_loss: 10.2298 - val_mse: 10.2298 - val_mae: 2.6896\n",
      "Epoch 20/100\n",
      "25/25 [==============================] - 0s 896us/step - loss: 6.1714 - mse: 6.1714 - mae: 1.8702 - val_loss: 4.4480 - val_mse: 4.4480 - val_mae: 1.6294\n",
      "Epoch 21/100\n",
      "25/25 [==============================] - 0s 855us/step - loss: 6.5327 - mse: 6.5327 - mae: 1.9453 - val_loss: 9.2148 - val_mse: 9.2148 - val_mae: 2.5752\n",
      "Epoch 22/100\n",
      "25/25 [==============================] - 0s 866us/step - loss: 5.9581 - mse: 5.9581 - mae: 1.8739 - val_loss: 3.9130 - val_mse: 3.9130 - val_mae: 1.5362\n",
      "Epoch 23/100\n",
      "25/25 [==============================] - 0s 881us/step - loss: 5.8199 - mse: 5.8199 - mae: 1.8671 - val_loss: 6.7289 - val_mse: 6.7289 - val_mae: 2.0292\n",
      "Epoch 24/100\n",
      "25/25 [==============================] - 0s 862us/step - loss: 5.9156 - mse: 5.9156 - mae: 1.8957 - val_loss: 4.0382 - val_mse: 4.0382 - val_mae: 1.5174\n",
      "Epoch 25/100\n",
      "25/25 [==============================] - 0s 887us/step - loss: 6.9331 - mse: 6.9331 - mae: 2.0776 - val_loss: 5.9414 - val_mse: 5.9414 - val_mae: 1.8924\n",
      "Epoch 26/100\n",
      "25/25 [==============================] - 0s 875us/step - loss: 4.5220 - mse: 4.5220 - mae: 1.6590 - val_loss: 4.5066 - val_mse: 4.5066 - val_mae: 1.6055\n",
      "Epoch 27/100\n",
      "25/25 [==============================] - 0s 861us/step - loss: 3.8456 - mse: 3.8456 - mae: 1.5160 - val_loss: 17.1593 - val_mse: 17.1593 - val_mae: 3.7768\n",
      "Epoch 28/100\n",
      "25/25 [==============================] - 0s 882us/step - loss: 11.7073 - mse: 11.7073 - mae: 2.7914 - val_loss: 4.2751 - val_mse: 4.2751 - val_mae: 1.5634\n",
      "Epoch 29/100\n",
      "25/25 [==============================] - 0s 874us/step - loss: 4.5039 - mse: 4.5039 - mae: 1.6578 - val_loss: 8.6020 - val_mse: 8.6020 - val_mae: 2.4718\n",
      "Epoch 30/100\n",
      "25/25 [==============================] - 0s 860us/step - loss: 5.8233 - mse: 5.8233 - mae: 1.9326 - val_loss: 2.9474 - val_mse: 2.9474 - val_mae: 1.3393\n",
      "Epoch 31/100\n",
      "25/25 [==============================] - 0s 871us/step - loss: 4.7135 - mse: 4.7135 - mae: 1.6952 - val_loss: 9.3018 - val_mse: 9.3018 - val_mae: 2.6700\n",
      "Epoch 32/100\n",
      "25/25 [==============================] - 0s 875us/step - loss: 5.5802 - mse: 5.5802 - mae: 1.8557 - val_loss: 2.8023 - val_mse: 2.8023 - val_mae: 1.3199\n",
      "Epoch 33/100\n",
      "25/25 [==============================] - 0s 855us/step - loss: 4.4377 - mse: 4.4377 - mae: 1.6446 - val_loss: 7.6554 - val_mse: 7.6554 - val_mae: 2.3268\n",
      "Epoch 34/100\n",
      "25/25 [==============================] - 0s 878us/step - loss: 4.9605 - mse: 4.9605 - mae: 1.7695 - val_loss: 6.8132 - val_mse: 6.8132 - val_mae: 2.2418\n",
      "Epoch 35/100\n",
      "25/25 [==============================] - 0s 862us/step - loss: 4.4297 - mse: 4.4297 - mae: 1.6483 - val_loss: 2.6359 - val_mse: 2.6359 - val_mae: 1.2730\n",
      "Epoch 36/100\n",
      "25/25 [==============================] - 0s 919us/step - loss: 3.8044 - mse: 3.8044 - mae: 1.5184 - val_loss: 3.1119 - val_mse: 3.1119 - val_mae: 1.4249\n",
      "Epoch 37/100\n",
      "25/25 [==============================] - 0s 875us/step - loss: 4.4547 - mse: 4.4547 - mae: 1.6731 - val_loss: 6.6933 - val_mse: 6.6933 - val_mae: 2.1537\n",
      "Epoch 38/100\n",
      "25/25 [==============================] - 0s 841us/step - loss: 9.0855 - mse: 9.0855 - mae: 2.4240 - val_loss: 2.5897 - val_mse: 2.5897 - val_mae: 1.2635\n",
      "Epoch 39/100\n",
      "25/25 [==============================] - 0s 849us/step - loss: 6.1196 - mse: 6.1196 - mae: 1.9992 - val_loss: 3.1004 - val_mse: 3.1004 - val_mae: 1.4257\n",
      "Epoch 40/100\n",
      "25/25 [==============================] - 0s 864us/step - loss: 3.0418 - mse: 3.0418 - mae: 1.3355 - val_loss: 3.8055 - val_mse: 3.8055 - val_mae: 1.6035\n",
      "Epoch 41/100\n",
      "25/25 [==============================] - 0s 843us/step - loss: 5.1743 - mse: 5.1743 - mae: 1.7699 - val_loss: 6.2326 - val_mse: 6.2326 - val_mae: 2.0734\n",
      "Epoch 42/100\n",
      "25/25 [==============================] - 0s 866us/step - loss: 5.8292 - mse: 5.8292 - mae: 1.9497 - val_loss: 2.7667 - val_mse: 2.7667 - val_mae: 1.3377\n",
      "Epoch 43/100\n",
      "25/25 [==============================] - 0s 884us/step - loss: 5.4125 - mse: 5.4125 - mae: 1.8738 - val_loss: 3.2034 - val_mse: 3.2034 - val_mae: 1.4561\n",
      "Epoch 44/100\n",
      "25/25 [==============================] - 0s 849us/step - loss: 9.3093 - mse: 9.3093 - mae: 2.5450 - val_loss: 6.3375 - val_mse: 6.3375 - val_mae: 2.0957\n",
      "Epoch 45/100\n",
      "25/25 [==============================] - 0s 860us/step - loss: 14.0933 - mse: 14.0933 - mae: 3.1150 - val_loss: 5.3616 - val_mse: 5.3616 - val_mae: 1.9504\n",
      "Epoch 46/100\n",
      "25/25 [==============================] - 0s 883us/step - loss: 7.3191 - mse: 7.3191 - mae: 2.2402 - val_loss: 6.3508 - val_mse: 6.3508 - val_mae: 2.1075\n",
      "Epoch 47/100\n",
      "25/25 [==============================] - 0s 850us/step - loss: 3.1818 - mse: 3.1818 - mae: 1.3573 - val_loss: 3.1801 - val_mse: 3.1801 - val_mae: 1.3600\n",
      "Epoch 48/100\n",
      "25/25 [==============================] - 0s 858us/step - loss: 3.4150 - mse: 3.4150 - mae: 1.4358 - val_loss: 7.4655 - val_mse: 7.4655 - val_mae: 2.3474\n",
      "Epoch 49/100\n",
      "25/25 [==============================] - 0s 867us/step - loss: 4.6931 - mse: 4.6931 - mae: 1.7287 - val_loss: 2.3498 - val_mse: 2.3498 - val_mae: 1.1717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/100\n",
      "25/25 [==============================] - 0s 855us/step - loss: 3.2376 - mse: 3.2376 - mae: 1.3900 - val_loss: 4.9173 - val_mse: 4.9173 - val_mae: 1.8036\n",
      "Epoch 51/100\n",
      "25/25 [==============================] - 0s 880us/step - loss: 3.7230 - mse: 3.7230 - mae: 1.5162 - val_loss: 2.1850 - val_mse: 2.1850 - val_mae: 1.1466\n",
      "Epoch 52/100\n",
      "25/25 [==============================] - 0s 858us/step - loss: 4.2887 - mse: 4.2887 - mae: 1.6301 - val_loss: 8.2510 - val_mse: 8.2510 - val_mae: 2.5133\n",
      "Epoch 53/100\n",
      "25/25 [==============================] - 0s 837us/step - loss: 3.9255 - mse: 3.9255 - mae: 1.5655 - val_loss: 4.5780 - val_mse: 4.5780 - val_mae: 1.8077\n",
      "Epoch 54/100\n",
      "25/25 [==============================] - 0s 856us/step - loss: 3.1754 - mse: 3.1754 - mae: 1.3925 - val_loss: 5.7104 - val_mse: 5.7104 - val_mae: 1.9960\n",
      "Epoch 55/100\n",
      "25/25 [==============================] - 0s 861us/step - loss: 7.4370 - mse: 7.4370 - mae: 2.2438 - val_loss: 4.2460 - val_mse: 4.2460 - val_mae: 1.7266\n",
      "Epoch 56/100\n",
      "25/25 [==============================] - 0s 850us/step - loss: 2.7639 - mse: 2.7639 - mae: 1.2812 - val_loss: 3.2389 - val_mse: 3.2389 - val_mae: 1.3915\n",
      "Epoch 57/100\n",
      "25/25 [==============================] - 0s 859us/step - loss: 3.2978 - mse: 3.2978 - mae: 1.4094 - val_loss: 2.0816 - val_mse: 2.0816 - val_mae: 1.1056\n",
      "Epoch 58/100\n",
      "25/25 [==============================] - 0s 849us/step - loss: 3.9955 - mse: 3.9955 - mae: 1.5778 - val_loss: 3.9508 - val_mse: 3.9508 - val_mae: 1.5821\n",
      "Epoch 59/100\n",
      "25/25 [==============================] - 0s 820us/step - loss: 4.0305 - mse: 4.0305 - mae: 1.5648 - val_loss: 13.0972 - val_mse: 13.0972 - val_mae: 3.3478\n",
      "Epoch 60/100\n",
      "25/25 [==============================] - 0s 829us/step - loss: 5.9562 - mse: 5.9562 - mae: 1.9865 - val_loss: 2.7587 - val_mse: 2.7587 - val_mae: 1.3505\n",
      "Epoch 61/100\n",
      "25/25 [==============================] - 0s 869us/step - loss: 4.4200 - mse: 4.4200 - mae: 1.6957 - val_loss: 16.9426 - val_mse: 16.9426 - val_mae: 3.8776\n",
      "Epoch 62/100\n",
      "25/25 [==============================] - 0s 841us/step - loss: 8.5206 - mse: 8.5206 - mae: 2.4566 - val_loss: 3.1860 - val_mse: 3.1860 - val_mae: 1.3848\n",
      "Epoch 63/100\n",
      "25/25 [==============================] - 0s 817us/step - loss: 4.4961 - mse: 4.4961 - mae: 1.6955 - val_loss: 2.0632 - val_mse: 2.0632 - val_mae: 1.1305\n",
      "Epoch 64/100\n",
      "25/25 [==============================] - 0s 834us/step - loss: 4.0991 - mse: 4.0991 - mae: 1.5831 - val_loss: 4.9542 - val_mse: 4.9542 - val_mae: 1.8388\n",
      "Epoch 65/100\n",
      "25/25 [==============================] - 0s 871us/step - loss: 4.0704 - mse: 4.0704 - mae: 1.5910 - val_loss: 16.3758 - val_mse: 16.3758 - val_mae: 3.8108\n",
      "Epoch 66/100\n",
      "25/25 [==============================] - 0s 834us/step - loss: 4.2273 - mse: 4.2273 - mae: 1.5936 - val_loss: 2.6538 - val_mse: 2.6538 - val_mae: 1.2488\n",
      "Epoch 67/100\n",
      "25/25 [==============================] - 0s 853us/step - loss: 2.3473 - mse: 2.3473 - mae: 1.1700 - val_loss: 5.8825 - val_mse: 5.8825 - val_mae: 2.0611\n",
      "Epoch 68/100\n",
      "25/25 [==============================] - 0s 857us/step - loss: 4.1934 - mse: 4.1934 - mae: 1.6276 - val_loss: 1.9880 - val_mse: 1.9880 - val_mae: 1.1115\n",
      "Epoch 69/100\n",
      "25/25 [==============================] - 0s 840us/step - loss: 2.5673 - mse: 2.5673 - mae: 1.2383 - val_loss: 4.2705 - val_mse: 4.2705 - val_mae: 1.6814\n",
      "Epoch 70/100\n",
      "25/25 [==============================] - 0s 838us/step - loss: 7.7894 - mse: 7.7894 - mae: 2.3487 - val_loss: 3.4557 - val_mse: 3.4557 - val_mae: 1.4673\n",
      "Epoch 71/100\n",
      "25/25 [==============================] - 0s 870us/step - loss: 5.7205 - mse: 5.7205 - mae: 1.9040 - val_loss: 2.7201 - val_mse: 2.7201 - val_mae: 1.2648\n",
      "Epoch 72/100\n",
      "25/25 [==============================] - 0s 851us/step - loss: 4.3359 - mse: 4.3359 - mae: 1.6860 - val_loss: 1.8789 - val_mse: 1.8789 - val_mae: 1.0743\n",
      "Epoch 73/100\n",
      "25/25 [==============================] - 0s 815us/step - loss: 4.7611 - mse: 4.7611 - mae: 1.7635 - val_loss: 2.4808 - val_mse: 2.4808 - val_mae: 1.2750\n",
      "Epoch 74/100\n",
      "25/25 [==============================] - 0s 837us/step - loss: 3.2452 - mse: 3.2452 - mae: 1.4233 - val_loss: 1.8824 - val_mse: 1.8824 - val_mae: 1.0501\n",
      "Epoch 75/100\n",
      "25/25 [==============================] - 0s 853us/step - loss: 2.7670 - mse: 2.7670 - mae: 1.2962 - val_loss: 1.8039 - val_mse: 1.8039 - val_mae: 1.0434\n",
      "Epoch 76/100\n",
      "25/25 [==============================] - 0s 836us/step - loss: 5.8286 - mse: 5.8286 - mae: 1.9403 - val_loss: 8.6243 - val_mse: 8.6243 - val_mae: 2.6538\n",
      "Epoch 77/100\n",
      "25/25 [==============================] - 0s 852us/step - loss: 5.1438 - mse: 5.1438 - mae: 1.8491 - val_loss: 5.0855 - val_mse: 5.0855 - val_mae: 1.9518\n",
      "Epoch 78/100\n",
      "25/25 [==============================] - 0s 869us/step - loss: 2.5310 - mse: 2.5310 - mae: 1.2301 - val_loss: 1.7979 - val_mse: 1.7979 - val_mae: 1.0465\n",
      "Epoch 79/100\n",
      "25/25 [==============================] - 0s 843us/step - loss: 2.2199 - mse: 2.2199 - mae: 1.1375 - val_loss: 1.7598 - val_mse: 1.7598 - val_mae: 1.0184\n",
      "Epoch 80/100\n",
      "25/25 [==============================] - 0s 863us/step - loss: 5.9312 - mse: 5.9312 - mae: 1.9080 - val_loss: 3.3288 - val_mse: 3.3288 - val_mae: 1.4436\n",
      "Epoch 81/100\n",
      "25/25 [==============================] - 0s 857us/step - loss: 6.8908 - mse: 6.8908 - mae: 2.1650 - val_loss: 2.8380 - val_mse: 2.8380 - val_mae: 1.3033\n",
      "Epoch 82/100\n",
      "25/25 [==============================] - 0s 838us/step - loss: 4.6993 - mse: 4.6993 - mae: 1.7626 - val_loss: 1.9515 - val_mse: 1.9515 - val_mae: 1.1089\n",
      "Epoch 83/100\n",
      "25/25 [==============================] - 0s 851us/step - loss: 4.8873 - mse: 4.8873 - mae: 1.7991 - val_loss: 2.3566 - val_mse: 2.3566 - val_mae: 1.2432\n",
      "Epoch 84/100\n",
      "25/25 [==============================] - 0s 865us/step - loss: 3.5592 - mse: 3.5592 - mae: 1.5116 - val_loss: 2.0842 - val_mse: 2.0842 - val_mae: 1.1566\n",
      "Epoch 85/100\n",
      "25/25 [==============================] - 0s 846us/step - loss: 5.5836 - mse: 5.5836 - mae: 1.9293 - val_loss: 2.3534 - val_mse: 2.3534 - val_mae: 1.1691\n",
      "Epoch 86/100\n",
      "25/25 [==============================] - 0s 856us/step - loss: 2.3608 - mse: 2.3608 - mae: 1.1760 - val_loss: 8.4142 - val_mse: 8.4142 - val_mae: 2.6413\n",
      "Epoch 87/100\n",
      "25/25 [==============================] - 0s 863us/step - loss: 3.7373 - mse: 3.7373 - mae: 1.5124 - val_loss: 1.9145 - val_mse: 1.9145 - val_mae: 1.0524\n",
      "Epoch 88/100\n",
      "25/25 [==============================] - 0s 850us/step - loss: 2.4583 - mse: 2.4583 - mae: 1.2197 - val_loss: 3.8918 - val_mse: 3.8918 - val_mae: 1.6824\n",
      "Epoch 89/100\n",
      "25/25 [==============================] - 0s 861us/step - loss: 1.9673 - mse: 1.9673 - mae: 1.0734 - val_loss: 3.8228 - val_mse: 3.8228 - val_mae: 1.6652\n",
      "Epoch 90/100\n",
      "25/25 [==============================] - 0s 884us/step - loss: 5.8542 - mse: 5.8542 - mae: 1.9937 - val_loss: 7.1669 - val_mse: 7.1669 - val_mae: 2.3734\n",
      "Epoch 91/100\n",
      "25/25 [==============================] - 0s 850us/step - loss: 5.3954 - mse: 5.3954 - mae: 1.9139 - val_loss: 4.3762 - val_mse: 4.3762 - val_mae: 1.7377\n",
      "Epoch 92/100\n",
      "25/25 [==============================] - 0s 865us/step - loss: 3.1744 - mse: 3.1744 - mae: 1.4247 - val_loss: 3.3936 - val_mse: 3.3936 - val_mae: 1.4779\n",
      "Epoch 93/100\n",
      "25/25 [==============================] - 0s 867us/step - loss: 4.0738 - mse: 4.0738 - mae: 1.6482 - val_loss: 3.0532 - val_mse: 3.0532 - val_mae: 1.3792\n",
      "Epoch 94/100\n",
      "25/25 [==============================] - 0s 851us/step - loss: 1.9533 - mse: 1.9533 - mae: 1.0662 - val_loss: 2.4659 - val_mse: 2.4659 - val_mae: 1.2813\n",
      "Epoch 95/100\n",
      "25/25 [==============================] - 0s 867us/step - loss: 2.1502 - mse: 2.1502 - mae: 1.1389 - val_loss: 2.0799 - val_mse: 2.0799 - val_mae: 1.0983\n",
      "Epoch 96/100\n",
      "25/25 [==============================] - 0s 894us/step - loss: 3.3047 - mse: 3.3047 - mae: 1.4423 - val_loss: 11.4434 - val_mse: 11.4434 - val_mae: 3.1519\n",
      "Epoch 97/100\n",
      "25/25 [==============================] - 0s 925us/step - loss: 10.0393 - mse: 10.0393 - mae: 2.6147 - val_loss: 3.0313 - val_mse: 3.0313 - val_mae: 1.4423\n",
      "Epoch 98/100\n",
      "25/25 [==============================] - 0s 928us/step - loss: 5.5064 - mse: 5.5064 - mae: 1.9470 - val_loss: 3.9160 - val_mse: 3.9160 - val_mae: 1.6259\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/25 [==============================] - 0s 907us/step - loss: 4.3844 - mse: 4.3844 - mae: 1.6988 - val_loss: 5.7092 - val_mse: 5.7092 - val_mae: 2.1129\n",
      "Epoch 100/100\n",
      "25/25 [==============================] - 0s 909us/step - loss: 4.0449 - mse: 4.0449 - mae: 1.6292 - val_loss: 2.2597 - val_mse: 2.2597 - val_mae: 1.2154\n"
     ]
    }
   ],
   "source": [
    "d1= random_result.best_params_\n",
    "\n",
    "keras_tuned=keras_reg_model(learning_rate=d1['learning_rate'],activation_function=d1['activation_function'],init=d1['init'],\n",
    "                                                                                       neuron1=d1['neuron1'],neuron2=d1['neuron2'])\n",
    "history2=keras_tuned.fit(x_train, y_train, validation_data=(x_test,y_test),\n",
    "                         epochs =d1['epochs'], batch_size=d1['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "21e327b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 247us/step\n",
      "94/94 [==============================] - 0s 279us/step\n",
      "Training set rmse : 1.541, Testing set rmse: 1.503\n"
     ]
    }
   ],
   "source": [
    "y_train_pred_tuned= keras_tuned.predict(x_train)\n",
    "y_test_pred_tuned= keras_tuned.predict(x_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "train_rmse_tuned = mean_squared_error(y_train,y_train_pred_tuned,squared=False)\n",
    "test_rmse_tuned = mean_squared_error(y_test, y_test_pred_tuned,squared=False)\n",
    "\n",
    "print('Training set rmse : %.3f, Testing set rmse: %.3f' % (train_rmse_tuned, test_rmse_tuned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f3d930f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>models</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>base model</td>\n",
       "      <td>135.199430</td>\n",
       "      <td>134.796142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tuned model</td>\n",
       "      <td>1.540949</td>\n",
       "      <td>1.503238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        models  train rmse   test rmse\n",
       "0   base model  135.199430  134.796142\n",
       "1  tuned model    1.540949    1.503238"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5; 1/10] START activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20\n",
      "[CV 3/5; 1/10] END activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20;, score=-45.979 total time=   1.0s\n",
      "[CV 4/5; 2/10] START activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 4/5; 2/10] END activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5;, score=-4.179 total time=   3.2s\n",
      "[CV 1/5; 5/10] START activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5\n",
      "[CV 1/5; 5/10] END activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5;, score=-222.799 total time=   0.8s\n",
      "[CV 5/5; 5/10] START activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5\n",
      "[CV 5/5; 5/10] END activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5;, score=-224.550 total time=   1.0s\n",
      "[CV 3/5; 6/10] START activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30\n",
      "[CV 3/5; 6/10] END activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30;, score=-2.771 total time=   5.2s\n",
      "[CV 5/5; 6/10] START activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30\n",
      "[CV 5/5; 6/10] END activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30;, score=-3.763 total time=   5.0s\n",
      "[CV 5/5; 7/10] START activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 5/5; 7/10] END activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-11284.237 total time=   1.6s\n",
      "[CV 3/5; 9/10] START activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30\n",
      "[CV 3/5; 9/10] END activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30;, score=-20.393 total time=   3.1s\n",
      "[CV 1/5; 2/10] START activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 1/5; 2/10] END activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5;, score=-1.762 total time=   2.8s\n",
      "[CV 1/5; 4/10] START activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 1/5; 4/10] END activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-14564.344 total time=  14.3s\n",
      "[CV 3/5; 8/10] START activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30\n",
      "[CV 3/5; 8/10] END activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30;, score=-229.223 total time=   0.8s\n",
      "[CV 5/5; 9/10] START activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30\n",
      "[CV 5/5; 9/10] END activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30;, score=-28.246 total time=   3.1s\n",
      "[CV 2/5; 2/10] START activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 2/5; 2/10] END activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5;, score=-3.868 total time=   2.4s\n",
      "[CV 4/5; 3/10] START activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 4/5; 3/10] END activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5;, score=-16317.460 total time=   1.7s\n",
      "[CV 2/5; 5/10] START activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5\n",
      "[CV 2/5; 5/10] END activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5;, score=-212.785 total time=   0.7s\n",
      "[CV 4/5; 5/10] START activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5\n",
      "[CV 4/5; 5/10] END activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5;, score=-219.835 total time=   1.0s\n",
      "[CV 2/5; 6/10] START activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30\n",
      "[CV 2/5; 6/10] END activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30;, score=-4.892 total time=   5.3s\n",
      "[CV 1/5; 7/10] START activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 1/5; 7/10] END activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-11468.643 total time=   1.7s\n",
      "[CV 2/5; 7/10] START activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 2/5; 7/10] END activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-11241.120 total time=   2.1s\n",
      "[CV 3/5; 7/10] START activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 3/5; 7/10] END activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-11250.133 total time=   1.4s\n",
      "[CV 1/5; 8/10] START activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30\n",
      "[CV 1/5; 8/10] END activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30;, score=-16465.189 total time=   0.7s\n",
      "[CV 2/5; 8/10] START activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30\n",
      "[CV 2/5; 8/10] END activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30;, score=-224.979 total time=   0.9s\n",
      "[CV 4/5; 9/10] START activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30\n",
      "[CV 4/5; 9/10] END activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30;, score=-4.337 total time=   3.3s\n",
      "[CV 2/5; 1/10] START activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20\n",
      "[CV 2/5; 1/10] END activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20;, score=-18.838 total time=   1.1s\n",
      "[CV 1/5; 3/10] START activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 1/5; 3/10] END activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5;, score=-16398.713 total time=   1.7s\n",
      "[CV 5/5; 3/10] START activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 5/5; 3/10] END activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5;, score=-16153.919 total time=   1.4s\n",
      "[CV 3/5; 5/10] START activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5\n",
      "[CV 3/5; 5/10] END activation_function=linear, batch_size=1000, epochs=25, init=uniform, learning_rate=0.001, neuron1=30, neuron2=5;, score=-205.442 total time=   0.8s\n",
      "[CV 1/5; 6/10] START activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30\n",
      "[CV 1/5; 6/10] END activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30;, score=-2.337 total time=   4.8s\n",
      "[CV 4/5; 6/10] START activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30\n",
      "[CV 4/5; 6/10] END activation_function=relu, batch_size=100, epochs=50, init=normal, learning_rate=0.001, neuron1=10, neuron2=30;, score=-5.283 total time=   5.9s\n",
      "[CV 4/5; 7/10] START activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 4/5; 7/10] END activation_function=linear, batch_size=2000, epochs=150, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-11398.011 total time=   1.6s\n",
      "[CV 5/5; 8/10] START activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30\n",
      "[CV 5/5; 8/10] END activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30;, score=-242.592 total time=   0.6s\n",
      "[CV 1/5; 10/10] START activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30\n",
      "[CV 1/5; 10/10] END activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30;, score=-1.759 total time=   4.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/5; 1/10] START activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20\n",
      "[CV 1/5; 1/10] END activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20;, score=-22.156 total time=   1.1s\n",
      "[CV 5/5; 2/10] START activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 5/5; 2/10] END activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5;, score=-2.846 total time=   3.1s\n",
      "[CV 5/5; 4/10] START activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 5/5; 4/10] END activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-14334.268 total time=  13.9s\n",
      "[CV 3/5; 10/10] START activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30\n",
      "[CV 3/5; 10/10] END activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30;, score=-4.742 total time=   4.7s\n",
      "[CV 3/5; 2/10] START activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 3/5; 2/10] END activation_function=linear, batch_size=500, epochs=100, init=uniform, learning_rate=0.01, neuron1=20, neuron2=5;, score=-1.949 total time=   2.7s\n",
      "[CV 2/5; 4/10] START activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 2/5; 4/10] END activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-14321.964 total time=  14.4s\n",
      "[CV 4/5; 8/10] START activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30\n",
      "[CV 4/5; 8/10] END activation_function=elu, batch_size=2000, epochs=25, init=uniform, learning_rate=0.001, neuron1=5, neuron2=30;, score=-236.821 total time=   0.7s\n",
      "[CV 2/5; 10/10] START activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30\n",
      "[CV 2/5; 10/10] END activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30;, score=-1.899 total time=   4.7s\n",
      "[CV 4/5; 1/10] START activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20\n",
      "[CV 4/5; 1/10] END activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20;, score=-51.052 total time=   1.2s\n",
      "[CV 3/5; 3/10] START activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 3/5; 3/10] END activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5;, score=-16093.307 total time=   1.9s\n",
      "[CV 4/5; 4/10] START activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 4/5; 4/10] END activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-14488.111 total time=  14.4s\n",
      "[CV 2/5; 9/10] START activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30\n",
      "[CV 2/5; 9/10] END activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30;, score=-37.162 total time=   2.7s\n",
      "[CV 4/5; 10/10] START activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30\n",
      "[CV 4/5; 10/10] END activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30;, score=-4.866 total time=   3.3s\n",
      "[CV 5/5; 1/10] START activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20\n",
      "[CV 5/5; 1/10] END activation_function=linear, batch_size=1000, epochs=25, init=normal, learning_rate=0.01, neuron1=10, neuron2=20;, score=-88.091 total time=   1.1s\n",
      "[CV 2/5; 3/10] START activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5\n",
      "[CV 2/5; 3/10] END activation_function=relu, batch_size=1000, epochs=80, init=zero, learning_rate=0.01, neuron1=20, neuron2=5;, score=-16141.453 total time=   1.8s\n",
      "[CV 3/5; 4/10] START activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20\n",
      "[CV 3/5; 4/10] END activation_function=relu, batch_size=50, epochs=80, init=zero, learning_rate=0.001, neuron1=5, neuron2=20;, score=-14276.561 total time=  14.4s\n",
      "[CV 1/5; 9/10] START activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30\n",
      "[CV 1/5; 9/10] END activation_function=relu, batch_size=1000, epochs=150, init=normal, learning_rate=0.001, neuron1=30, neuron2=30;, score=-1.898 total time=   2.8s\n",
      "[CV 5/5; 10/10] START activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30\n",
      "[CV 5/5; 10/10] END activation_function=linear, batch_size=100, epochs=50, init=normal, learning_rate=0.01, neuron1=10, neuron2=30;, score=-1.767 total time=   3.3s\n"
     ]
    }
   ],
   "source": [
    "result=pd.DataFrame({'models':['base model','tuned model'],'train rmse':[train_rmse,train_rmse_tuned],\n",
    "                     'test rmse':[test_rmse,test_rmse_tuned]})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24758f4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaaebf0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
